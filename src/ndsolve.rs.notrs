#![allow(non_snake_case)]
#![allow(dead_code)]

use rand::Rng;
use ndarray::prelude::*;

use crate::firm;
use crate::linalg;
use crate::options;
use crate::stats;
use crate::utility;

pub enum DerivativeOrder {
    Zero,
    One,
    Two,
}

pub struct FPISolver<'a> {
    pub firms: &'a Vec<firm::Firm>,
    pub utility: &'a mut dyn utility::Utility, // "whatever has the traits"
    // stats?
    F: usize,                       // number of firms (firms.len())
    Fi: Vec<(usize, usize, usize)>, // "[)" style indices for firm blocks (start, end, size)
    J: usize,                       // firms.iter().map(|f| f.products).sum()
    K: usize,                       // number of characteristics
    X: Array,                    // K x J characteristics
    c: Array,                    // c.len() == J
    p: Array,                    // p.len() == J
    m: Array,                    // markups, m.len() == J
    pr: Array,                   // profits, pr.len() == F
    P: Array,                    // probabilities, P.len() == J

    _id: FPISolverIterData, // data used during solver iterations
}

pub struct FPISolverIterData {
    I: usize,        // "individuals" (sample size)
    V: Array,     // V.len() == I x J
    U: Array,     // U.len() == I x J
    ujmax: Array, // ujmax.len() == I, for expfloat corrections
    bimax: usize,    // for budget corrections
    bmax: f64,       // for budget corrections
    DpU: Array,   // DpU.len() == I x J
    DppU: Array,  // DppU.len() == I x J
    PL: Array,    // PL.len() == I x J
    DpUPL: Array, // DpUPL.len() == I x J
    L: Array,     // L.len() == J, Lambda "matrix" (diagonals)
    G: Array,     // G.len() == J x J, Gamma matrix NOTE: we only need \tilde{G}...
    z: Array,     // P.len() == J, zeta map
    phi: Array,   // phi.len() == J, "phi" map (p - c - z(p))
    cg: Array,    // cg.len() == J, combined gradient (L(p) * phi(p), componentwise)
}

impl FPISolverIterData {
    fn empty() -> FPISolverIterData {
        return FPISolverIterData {
            I: 0,           // "individuals";
            U: array![],      // zeros?
            V: array![],      //
            ujmax: array![],  // for expfloat corrections
            bimax: 0_usize, // for budget corrections
            bmax: 0.0_f64,  // for budget corrections
            DpU: array![],    // zeros?
            DppU: array![],   // zeros?
            DpUPL: array![],  // zeros?
            PL: array![],     // zeros?
            L: array![],
            G: array![], // TODO: store only blocks
            z: array![],
            phi: array![],
            cg: array![],
        };
    }

    fn sized(I: usize, J: usize) -> FPISolverIterData {
        return FPISolverIterData {
            I: I,                       // "individuals";
            U: Array::zeros(I, J),     // zeros?
            V: Array::zeros(I, J),     //
            ujmax: Array::zeros(I, 1), // for expfloat corrections
            bimax: 0_usize,             // for budget corrections
            bmax: 0.0_f64,              // for budget corrections
            DpU: Array::zeros(I, J),   // zeros?
            DppU: Array::zeros(I, J),  // zeros?
            DpUPL: Array::zeros(I, J), // zeros?
            PL: Array::zeros(I, J),    // zeros?
            L: Array::zeros(J, 1),
            G: Array::zeros(J, J), // TODO: store only blocks
            z: Array::zeros(J, 1),
            phi: Array::zeros(J, 1),
            cg: Array::zeros(J, 1),
        };
    }
}

impl FPISolver<'_> {
    pub fn new<'a>(
        firms: &'a Vec<firm::Firm>,
        utility: &'a mut dyn utility::Utility, // anything implementing the traits
    ) -> FPISolver<'a> {
        let F = firms.len();
        let J = firms.iter().map(|f| f.Jf).sum();

        assert!(firms[0].X.len() % firms[0].Jf == 0);
        let K = firms[0].X.len() / firms[0].Jf;
        for f in 1..firms.len() {
            assert!(firms[f].X.len() % firms[f].Jf == 0);
            assert!(firms[f].X.len() / firms[f].Jf == K);
        }

        let mut solver = FPISolver {
            firms: firms,
            utility: utility,
            F: F,
            J: J,
            K: K,
            Fi: Vec::<(usize, usize, usize)>::with_capacity(F),
            X: Array::zeros(K, J),
            c: Array::zeros(J, 1),
            p: Array::zeros(J, 1),
            m: Array::zeros(J, 1),
            pr: Array::zeros(F, 1),
            P: Array::zeros(J, 1),
            _id: FPISolverIterData::empty(), // can't size until we know I
        };

        let mut s: usize = 0;
        for firm in firms.iter() {
            let e = s + firm.Jf;
            solver.Fi.push((s, e, firm.Jf));
            // memcpy? faster?
            for j in 0..firm.Jf {
                solver.c[s + j] = firm.c[j];
                for k in 0..solver.K {
                    let Xidx = solver.K * (s + j) + k;
                    let Fidx = solver.K * j + k;
                    solver.X[Xidx] = firm.X[Fidx];
                }
            }
            s = e;
        }

        return solver;
    }

    pub fn solve(
        &mut self,
        samples: usize,
        p0: Option<&Array>,
        opts: &options::FPISolveOptions,
    ) -> Result<Option<stats::FPISolveStats>, Option<stats::FPISolveStats>> {
        // define solver data (we can size now, with samples)
        self._id = FPISolverIterData::sized(samples, self.J);

        self._set_initial_prices(p0, opts.start_at_costs);

        // sample parameters needed to compute
        let corrected: bool;
        match self.utility.sample(samples) {
            Some((bi, bm)) => {
                self._id.bimax = bi;
                self._id.bmax = bm;
                corrected = opts.corrected;
            }
            None => {
                corrected = false;
            }
        }

        // pre-computable "values" V for U(p) = F(p|a,b) + V
        self.utility.values(self.J, &self.X, &mut self._id.V);

        // run iterations
        let mut stats = stats::FPISolveStats::start(opts.max_iter);
        let mut solved: bool = false;
        let mut do_stats: bool;
        let mut fp_norm: f64;
        let mut cg_norm: f64;
        for iter in 0..opts.max_iter {
            stats.start_iter(iter); // always start, maybe store

            self._iterprep();
            if corrected {
                self._zeta_c();
            } else {
                self._zeta_u();
            }
            self._combgradz();

            // infinity/sup norm of FP step and combined gradient
            fp_norm = self._id.phi.fold(0.0_f64, |v, b| v.abs().max(b));
            cg_norm = self._id.cg.fold(0.0_f64, |v, b| v.abs().max(b));

            do_stats = (iter == 0) || ((opts.stats_every > 0) && (iter % opts.stats_every == 0));
            if do_stats {
                stats.finish_iter(&self.p, &self.P, fp_norm, cg_norm);
                if opts.verbose {
                    println!("{}", stats.latest());
                }
            }

            // both conditions, or just one?
            if fp_norm <= opts.tolerance || cg_norm <= opts.tolerance {
                solved = true;
                // TODO: we need to have a way of at least always storing
                // initial and final "stats".
                stats.finish_iter(&self.p, &self.P, fp_norm, cg_norm);
                if opts.verbose {
                    println!("{}", stats.latest());
                }
                break;
            }

            // actual step
            p = c + self._id.z;
        }
        stats.finish();

        if opts.stats_every > 0 {
            if solved {
                Ok(Some(stats))
            } else {
                Err(Some(stats))
            }
        } else {
            if solved {
                Ok(None)
            } else {
                Err(None)
            }
        }
    }

    /// TODO: copy prices? return prices? add to firms data?
    pub fn prices(&self) -> &Vec<f64> {
        return &(self.p);
    }

    pub fn probabilities(&mut self) -> &Vec<f64> {
        self._evalprep();
        return &(self.P);
    }

    pub fn profits(&mut self) -> &Vec<f64> {
        self._evalprep();
        self._profits();
        return &(self.pr);
    }

    /// private methods below

    fn _set_initial_prices(&mut self, p0: Option<&Array>, start_at_costs: bool) {
        // random prices in [ c/2 , 3/2c ] if not specified
        match p0 {
            Some(p0) => {
                self.p.assign(&p0);
            }
            None => {
                if start_at_costs {
                    self.p.assign(&self.c);
                } else {
                    for j in 0..self.J {
                        let r = rand::thread_rng().gen_range(0.5_f64..1.5_f64);
                        self.p[j] = r * self.c[j];
                    }
                }
            }
        }
    }

    /// compute markups, utilities, their derivatives, probabilities, and
    /// the L/G "matrices" we use in iteratively solving.
    fn _iterprep(&mut self) {
        self._markups();
        self._utilities(DerivativeOrder::Two);
        self._probabilities();
        self._lamgam();
    }

    fn _evalprep(&mut self) {
        self._markups();
        self._utilities(DerivativeOrder::Zero);
        self._probabilities();
    }

    /// m <- p - c ; note though that if p = c + z(p'), m = z(p')
    /// (that is, the markups in a FPI are the _previous_ z values...)
    fn _markups(&mut self) {
        self.m = self.p - self.c;
    }

    /// evaluate utilities given passed interface
    fn _utilities(&mut self, ord: DerivativeOrder) {
        // evaluate utilities
        match ord {
            DerivativeOrder::Zero => {
                self.utility.eval_UpD0(&self.p, &mut self._id.U);
            }
            DerivativeOrder::One => {
                self.utility
                    .eval_UpD1(&self.p, &mut self._id.U, &mut self._id.DpU);
            }
            DerivativeOrder::Two => {
                self.utility.eval_UpD2(
                    &self.p,
                    &mut self._id.U,
                    &mut self._id.DpU,
                    &mut self._id.DppU,
                );
            }
        }

        // U <- U + V , ujmax[i] <- max{ 0, max_j U[i,j] }
        self._id.U += self._id.V;
        self._id.ujmax = self._id.U.fold_axis(Axis(1), 0.0_f64, |u, v| => u.max(v));
    }

    /// compute (mixed) Logit probabilities
    fn _probabilities(&mut self) {
        // Compute
        //
        //      PL[i,j] = exp(U[i,j]-ujmax[i]) / S[i]
        //
        // where
        //
        //      S[i] = exp(-ujmax[i]) + sum_k exp( U[i,k] - ujmax[i] )
        //
        let mut idx: usize;

        self._id.PL = self._id.U

        let S = self._id.ujmax.mapv(|u| => (-u).exp())
                + self._id.PL

        for i in 0..self._id.I {
            let mut S = (-self._id.ujmax[i]).exp(); // e^{-ujmax[i]}
            for j in 0..self.J {
                idx = self._id.I * j + i;
                self._id.PL[idx] = (self._id.U[idx] - self._id.ujmax[i]).exp();
                S += self._id.PL[idx];
            }
            for j in 0..self.J {
                idx = self._id.I * j + i;
                self._id.PL[idx] /= S; // divide each by the sum of exp's
            }
        }

        // P = PL' 1 / I (could just sum over 0, if that is shaped right)
        self.P = self._id.PL.t().sum_axis(Axis(1)) / (self._id.I as f64);
    }

    /// Compute the "Lambda" and "Gamma" matrices from the papers. Note
    /// that "Lambda" (`L`) is a diagonal matrix, but "Gamma" (`G`) is full.
    fn _lamgam(&mut self) {
        // Also note some theory:
        //
        //     DpU * PL -> 0 as p -> b
        //
        // so long as
        //
        //       DpPL -> 0 and - DppU/(DpU)^2 is bounded as p -> b
        //
        // as follows from L'Hopital's rule. Moreover, this is sufficient but
        // not necessary, though boundedness of that ratio of derivatives is
        // a totally reasonable ask. We could enforce this here, or via how
        // DppU and DpU are evaluated.

        let If = self._id.I as f64;

        // DpUPL = DpU * PL (componentwise)
        self._id.DpUPL = self._id.DpU * self._id.PL; // is this writing into or alloc?

        // L = DpUPL' 1 / I
        L = self._id.DpUPL.t().sum_axis(Axis(1)) / If; // is this writing into or alloc?

        // G[Fi[f],Fi[f]] = PL[:,Fi[f]]' DpUPL[:, Fi[f]]
        //
        // TODO: are we storing as full matrix, or vector of matrices?
        // To the degree the firm-block matrices are all that is required
        // we should probably only store those.
        self._id.G = self._id.PL.t().dot(self._id.DpUPL) / If; // is this writing into or alloc?

        // for f in 0..self.F {
        //     let PLf = self._id.PL.slice(s![.., self.Fi[f].0..self.Fi[f].1]);
        //     let DpUPLf = self._id.DpUPLf.slice(s![.., self.Fi[f].0..self.Fi[f].1]);
        //     self._id.G[f] = PLf.t().dot(DpUPLf) / If;
        // }
    }

    // Uncorrected "zeta map"
    //
    //      z <- inv(L(p)) * ( \tilde{G}(p)' * m - P )
    //
    fn _zeta_u(&mut self) {
        self._zeta_b();
        self._id.z = self._id.z / self._id.L; // componentwise
        self._id.phi = self.m - self._id.z;
    }

    // Corrected zeta map
    //
    //      z <- inv(L(p)) * ( \tilde{G}(p)' * m - P )
    //
    // for all prices < maxinc, "corrected" otherwise. The correction
    // is a bit complicated for notes here, but in the paper.
    fn _zeta_c(&mut self) {
        self._zeta_b();

        // nominally z <- inv(L) * z, but with corrections
        // for products whose prices are above the population limit
        // on incomes. The correction is
        //
        //     z[j] = omega[maxinci,j] * ( p[j] - maxinc ) + PL[maxinci,{f}]' * m[{f}]
        //
        for f in 0..self.F {
            let mut prFmi = 0.0_f64;
            for j in self.Fi[f].0..self.Fi[f].1 {
                prFmi += self._id.PL[self._id.I * j + self._id.bimax] * self.m[j];
            }

            for j in self.Fi[f].0..self.Fi[f].1 {
                if self.p[j] > self._id.bmax {
                    // correction term - price j is too high; is this right?
                    // p - bmax, not bmax - p[j]?
                    self._id.z[j] = self._id.DppU[self._id.I * j + self._id.bimax]
                        * (self.p[j] - self._id.bmax)
                        + prFmi;
                } else if self._id.L[j] >= -1.0e-20 {
                    // L[j] <= 0, so L[j] ~ 0.0, i.e. PL ~ 0.0
                    // use a modification of extended map instead of what is calculated above
                    //
                    //      z[j] = PL[maxinci,{f}]' * m[{f}]
                    //
                    // we exclude the "DppU[ujmax, j] * ( p[j] - maxinc )" term expecting
                    // p[j] to be at least close to bmax
                    self._id.z[j] = prFmi;
                } else {
                    self._id.z[j] /= self._id.L[j];
                }
            }
        }

        // compute phi = p - c - z also (self.m updated with _iterprep)
        self._id.phi = self.m - self._id.z;
    }

    /// z <- \tilde{GAMp}' * m - P
    fn _zeta_b(&mut self) {
        self._id.z.assign(&self.P);
        for f in 0..self.F {
            let Gf = self._id.G.slice(s![self.Fi[f].0..self.Fi[f].1, self.Fi[f].0..self.Fi[f].1]);
            let mf = self.m.slice(s![self.Fi[f].0..self.Fi[f].1]);
            let zf = self._id.cg.slice(s![self.Fi[f].0..self.Fi[f].1]);
            zf = Gf.t().dot(&mf) - zf;
        }
    }

    /// cg <- L(p) phi(p) = L(p) ( p - c - z(p) )
    fn _combgradz(&mut self) {
        self._id.cg = self._id.L * self._id_phi;
    }

    /// cg <- (L(p) - \tidle{G}(p))'m + P(p) (literal formula)
    fn _combgrad(&mut self) {
        self._id.cg = self._id.L * self.m + self.P;

        for f in 0..self.F {
            let Gf = self._id.G.slice(s![self.Fi[f].0..self.Fi[f].1, self.Fi[f].0..self.Fi[f].1]);
            let mf = self.m.slice(s![self.Fi[f].0..self.Fi[f].1]);
            let cgf = self._id.cg.slice(s![self.Fi[f].0..self.Fi[f].1]);
            cgf -= Gf.t().dot(&mf);
        }
    }

    fn _profits(&mut self) {
        for f in 0..self.F {
            let Pf = self.P.slice(s![self.Fi[f].0..self.Fi[f].1]);
            let mf = self.m.slice(s![self.Fi[f].0..self.Fi[f].1]);
            self.pr[f] = Pf.dot(&mf);
        }
    }
}

#[cfg(test)]
mod tests {

    use super::*;
    use rand::Rng;
    use rand_distr::{LogNormal, Normal};

    static TEST_I: usize = 10;
    static TEST_F: usize = 3;
    static TEST_K: usize = 5;

    #[test]
    fn test_solver_linu() {
        let mut firms: Vec<firm::Firm> = vec![];
        for f in 0..TEST_F {
            let Jf: usize = 5; // better to be like random from 3 to 5 or something
            let mut firm = firm::Firm {
                name: "test".to_string(),
                Jf: Jf,
                c: linalg::randmat(Jf, 1, 1.0, 2.0),
                p: linalg::randmat(Jf, 1, 1.5, 2.5),
                X: linalg::randmat(TEST_K, Jf, -1.0, 1.0),
            };
            firms.push(firm);
        }

        let a_dist = LogNormal::<f64>::new(2.0, 3.0).unwrap();
        let W_dist = Normal::<f64>::new(0.0, 1.0).unwrap();
        let mut linu =
            utility::LinUtility::<LogNormal<f64>, Normal<f64>>::new(TEST_K, &a_dist, &W_dist);

        let mut solver = FPISolver::new(&firms, &mut linu);

        let opts = options::FPISolveOptions::default();
        match solver.solve(TEST_I, None, &opts) {
            Ok(stats) => println!("{}", stats.unwrap().latest()),
            Err(stats) => assert!(false),
        }
    }

    #[test]
    fn test_solver_loru() {
        let mut firms: Vec<firm::Firm> = vec![];
        for f in 0..TEST_F {
            let Jf: usize = 5; // better to be like random from 3 to 5 or something
            let mut firm = firm::Firm {
                name: "test".to_string(),
                Jf: Jf,
                c: linalg::randmat(Jf, 1, 1.0, 2.0),
                p: linalg::randmat(Jf, 1, 1.5, 2.5),
                X: linalg::randmat(TEST_K, Jf, -1.0, 1.0),
            };
            firms.push(firm);
        }

        let a_dist = LogNormal::<f64>::new(2.0, 3.0).unwrap();
        let b_dist = LogNormal::<f64>::new(10.0, 100.0).unwrap();
        let W_dist = Normal::<f64>::new(0.0, 1.0).unwrap();
        let mut loru = utility::LORUUtility::<LogNormal<f64>, LogNormal<f64>, Normal<f64>>::new(
            TEST_K, &a_dist, &b_dist, &W_dist,
        );

        let mut solver = FPISolver::new(&firms, &mut loru);

        let opts = options::FPISolveOptions::default();
        match solver.solve(TEST_I, None, &opts) {
            Ok(stats) => println!("{}", stats.unwrap().latest()),
            Err(stats) => assert!(false),
        }
    }

    /// this is for periodic checks of whether this "scales"
    // #[test]
    // fn test_solver_scale() {
    //     let I = 1000;
    //     let F = 10;
    //     let K = 5;

    //     let mut firms: Vec<firm::Firm> = vec![];
    //     for f in 0..F {
    //         let Jf: usize = 20; // better to be like random from 3 to 5 or something
    //         let mut firm = firm::Firm {
    //             name: "test".to_string(),
    //             Jf: Jf,
    //             c: linalg::randmat(Jf, 1, 1.0, 2.0),
    //             p: linalg::randmat(Jf, 1, 1.5, 2.5),
    //             X: linalg::randmat(K, Jf, -1.0, 1.0),
    //         };
    //         firms.push(firm);
    //     }

    //     let a_dist = LogNormal::<f64>::new(2.0, 3.0).unwrap();
    //     let W_dist = Normal::<f64>::new(0.0, 1.0).unwrap();
    //     let mut linu = utility::LinUtility::<LogNormal<f64>, Normal<f64>>::new(K, &a_dist, &W_dist);

    //     let mut solver = FPISolver::new(&firms, &mut linu);

    //     let mut opts = options::FPISolveOptions::default();
    //     opts.verbose = true;
    //     match solver.solve(I, None, &opts) {
    //         Ok(stats) => println!("{}", stats.unwrap().latest()),
    //         Err(stats) => assert!(false),
    //     }
    // }
}
